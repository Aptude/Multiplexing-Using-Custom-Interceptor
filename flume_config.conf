agent.channels= hdfschannelfile1 hdfschannelfile2
agent.sources=spoolsource
agent.sinks= hdfssinkfile1 hdfssinkfile2
agent.channels.type=memory
agent.channels.hdfschannelfile1.type=memory
agent.channels.hdfschannelfile2.type=memory

agent.channels.hdfschannelfile1.capacity = 100000
agent.channels.hdfschannelfile1.transactionCapacity = 10000
agent.channels.hdfschannelfile2.capacity = 100000
agent.channels.hdfschannelfile2.transactionCapacity = 10000

agent.sources.spoolsource.type=spooldir
agent.sources.spoolsource.spoolDir=/tmp/logs
agent.sources.spoolsource.fileHeader=true
agent.sources.spoolsource.deserializer.maxLineLength=200000
agent.sources.spoolsource.channels=hdfschannelfile1 hdfschannelfile2
agent.sources.spoolsource.interceptors=i1 i2
agent.sources.spoolsource.interceptors.i1.type=org.apache.flume.interceptor.TimestampInterceptor$Builder
agent.sources.spoolsource.interceptors.i1.preserveExisting = false
agent.sources.spoolsource.interceptors.i2.type=CustomInterceptor$Builder
agent.sources.spoolsource.selector.type=multiplexing
agent.sources.spoolsource.selector.header=fileloc
agent.sources.spoolsource.selector.mapping.file1=  hdfschannelfile1
agent.sources.spoolsource.selector.mapping.file2= hdfschannelfile2
agent.sources.spoolsource.deletePolicy=immediate

agent.sinks.hdfssinkfile1.channel=hdfschannelfile1
agent.sinks.hdfssinkfile1.type=hdfs
agent.sinks.hdfssinkfile1.hdfs.path=hdfs://localhost.localdomain:8020/user/hive/warehouse/file1_logs
agent.sinks.hdfssinkfile1.serializer = CustomSerializer1$Builder
agent.sinks.hdfssinkfile1.hdfs.fileType=DataStream
agent.sinks.hdfssinkfile1.hdfs.batchSize = 10000

agent.sinks.hdfssinkfile2.channel=hdfschannelfile2
agent.sinks.hdfssinkfile2.type=hdfs
agent.sinks.hdfssinkfile2.hdfs.path=hdfs://localhost.localdomain:8020/user/hive/warehouse/file2_logs
agent.sinks.hdfssinkfile2.serializer = CustomSerializer1$Builder
agent.sinks.hdfssinkfile2.hdfs.fileType=DataStream
agent.sinks.hdfssinkfile2.hdfs.batchSize = 10000
